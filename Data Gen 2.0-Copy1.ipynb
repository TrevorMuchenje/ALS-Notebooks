{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " key point of the notebook is the split of the df into 3 separate dfs wrt hvc, mvc and lvc and then the dfs are merged back together. And reduce size of n_names please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize Faker\n",
    "fake=Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "n_names=20000\n",
    "for n in range(n_names):\n",
    "    names.append(fake.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_segment = ['High Value','Medium Value', 'Low Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_segments=np.random.choice(customer_segment,n_names, p=[.20,.25,.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id =[]\n",
    "for i in range(n_names):\n",
    "    user_id.append(np.random.randint(1,2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=[user_id,names,customer_segments]\n",
    "\n",
    "df=pd.DataFrame(variables).transpose()\n",
    "\n",
    "df.columns=[\"User ID\", \"Customer Name\",\"customer_segment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>customer_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1521</td>\n",
       "      <td>Austin Meyers</td>\n",
       "      <td>Medium Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1523</td>\n",
       "      <td>Melanie Stafford</td>\n",
       "      <td>Low Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1215</td>\n",
       "      <td>Kathryn Guerrero MD</td>\n",
       "      <td>Medium Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>457</td>\n",
       "      <td>Stacy Jacobs</td>\n",
       "      <td>Medium Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1559</td>\n",
       "      <td>Christopher Taylor</td>\n",
       "      <td>Low Value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User ID        Customer Name customer_segment\n",
       "0    1521        Austin Meyers     Medium Value\n",
       "1    1523     Melanie Stafford        Low Value\n",
       "2    1215  Kathryn Guerrero MD     Medium Value\n",
       "3     457         Stacy Jacobs     Medium Value\n",
       "4    1559   Christopher Taylor        Low Value"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>customer_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1999</td>\n",
       "      <td>17979</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>241</td>\n",
       "      <td>Christopher Smith</td>\n",
       "      <td>Low Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>11094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID      Customer Name customer_segment\n",
       "count     20000              20000            20000\n",
       "unique     1999              17979                3\n",
       "top         241  Christopher Smith        Low Value\n",
       "freq         23                  9            11094"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### regions\n",
    "regions=[\"HN\",\"HS\",\"MAT\",\"MVO\",\"Mash E+CZA\",\"MID\",\"MAN\",\"Mash C+W\"]\n",
    "df[\"Region\"]=np.random.choice(regions,n_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### splitting the df by customer segment, assign bundles and concatenate back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hvc\n",
    "hvcdf = df[df['customer_segment'] == 'High Value'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>customer_segment</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1087</td>\n",
       "      <td>Laura Henderson</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>732</td>\n",
       "      <td>Christina Bauer</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash C+W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1774</td>\n",
       "      <td>William Martinez</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>272</td>\n",
       "      <td>Steven Gonzalez</td>\n",
       "      <td>High Value</td>\n",
       "      <td>MID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1452</td>\n",
       "      <td>Nicole Pittman</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash E+CZA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID     Customer Name customer_segment      Region\n",
       "13    1087   Laura Henderson       High Value          HS\n",
       "20     732   Christina Bauer       High Value    Mash C+W\n",
       "22    1774  William Martinez       High Value          HN\n",
       "23     272   Steven Gonzalez       High Value         MID\n",
       "29    1452    Nicole Pittman       High Value  Mash E+CZA"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvcdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3962"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvcdf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trevor.muchenje\\AppData\\Local\\Continuum\\anaconda3\\envs\\recsys\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "hvc = ['Private WiFi Bundle 75GB', 'Data Daily Bundle 2GB', 'Private WiFi Bundle 50GB',\n",
    "       'Daily Data Bouquet 2GB', 'Private WiFi Bundle  15GB', 'Private WiFi Bundle 25GB', \n",
    "       '2hr data bundle 1.5GB', 'eLearning Bundle 10GB $1120', 'WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasai Bouquet',\n",
    "       'WhatsApp + Twitter Monthly Bundle $3']\n",
    "hvcdf['data_subscriptions'] = np.random.choice(hvc,hvcdf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mvc\n",
    "mvcdf = df[df['customer_segment'] == 'Medium Value'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>customer_segment</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1521</td>\n",
       "      <td>Austin Meyers</td>\n",
       "      <td>Medium Value</td>\n",
       "      <td>MID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1215</td>\n",
       "      <td>Kathryn Guerrero MD</td>\n",
       "      <td>Medium Value</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>457</td>\n",
       "      <td>Stacy Jacobs</td>\n",
       "      <td>Medium Value</td>\n",
       "      <td>HN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>212</td>\n",
       "      <td>Adam Ruiz</td>\n",
       "      <td>Medium Value</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1800</td>\n",
       "      <td>Angela Mitchell</td>\n",
       "      <td>Medium Value</td>\n",
       "      <td>MAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User ID        Customer Name customer_segment Region\n",
       "0    1521        Austin Meyers     Medium Value    MID\n",
       "2    1215  Kathryn Guerrero MD     Medium Value     HS\n",
       "3     457         Stacy Jacobs     Medium Value     HN\n",
       "6     212            Adam Ruiz     Medium Value     HS\n",
       "7    1800      Angela Mitchell     Medium Value    MAT"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvcdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trevor.muchenje\\AppData\\Local\\Continuum\\anaconda3\\envs\\recsys\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mvc = ['Data Weekly Bundle 700MB', 'eLearning Bundle 10GB $1120',\n",
    "       'WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasai Bouquet', 'Data Weekly Bundle 350MB', '2hr data bundle 1.5GB', \n",
    "       'Instagram (400MB) + 400MB Sasai Bouquet', 'Daily Data Bouquet 250MB', 'Daily Data Bouquet 40MB','Data Daily Bundle 40MB',\n",
    "       'Twitter (45MB)+ LinkedIn 25MB + 45MB Sasai Bouquet','Facebook + Instagram Weekly Bundle $1',\n",
    "       'Twitter (140MB)+ LinkedIn 70MB + 140MB Sasai Bouquet']\n",
    "mvcdf['data_subscriptions'] = np.random.choice(mvc,mvcdf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lvc\n",
    "lvcdf = df[df['customer_segment'] == 'Low Value'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>customer_segment</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1523</td>\n",
       "      <td>Melanie Stafford</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>MAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1559</td>\n",
       "      <td>Christopher Taylor</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>MVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1291</td>\n",
       "      <td>Edwin Moreno Jr.</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>Mash C+W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1325</td>\n",
       "      <td>Kellie Clark</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>Mash C+W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>920</td>\n",
       "      <td>Kevin Hull</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>Mash C+W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User ID       Customer Name customer_segment    Region\n",
       "1    1523    Melanie Stafford        Low Value       MAT\n",
       "4    1559  Christopher Taylor        Low Value       MVO\n",
       "5    1291    Edwin Moreno Jr.        Low Value  Mash C+W\n",
       "8    1325        Kellie Clark        Low Value  Mash C+W\n",
       "9     920          Kevin Hull        Low Value  Mash C+W"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvcdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trevor.muchenje\\AppData\\Local\\Continuum\\anaconda3\\envs\\recsys\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "lvc = ['Twitter Monthly Balance 400MB', 'Data Weekly Bouquet 160MB', 'WhatsApp + Twitter Weekly Bundle $1', 'WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasai Bouquet',\n",
    "       'Twitter (140MB)+ LinkedIn 70MB + 140MB Sasai Bouquet', 'Data Weekly Bundle 350MB', 'Daily Data Bouquet 80MB',\n",
    "       'WhatsApp (45MB)+ Pinterest 25MB + 45MB Sasai Bouquet', 'WhatsApp (20MB)+ Pinterest 10MB + 20MB Sasai Bouquet',\n",
    "       'Data Daily Bundle 600MB', 'Data Weekly Bundle 300MB', 'Facebook (45MB)+ SnapChat 25MB + 45MB Sasai Bouquet',\n",
    "       '1hr data bundle 1GB', 'Daily Data Bouquet 20MB', 'Instagram (20MB) + 20MB Sasai Bouquet', 'Facebook + Instagram Daily Bundle $0.3'\n",
    "       ]\n",
    "lvcdf['data_subscriptions'] = np.random.choice(lvc,lvcdf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvcdf.shape[0]+mvcdf.shape[0]+hvcdf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### concatenating the three dataframes\n",
    "dfc = pd.concat([hvcdf, mvcdf, lvcdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>customer_segment</th>\n",
       "      <th>Region</th>\n",
       "      <th>data_subscriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1087</td>\n",
       "      <td>Laura Henderson</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HS</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>732</td>\n",
       "      <td>Christina Bauer</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash C+W</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1774</td>\n",
       "      <td>William Martinez</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HN</td>\n",
       "      <td>Private WiFi Bundle 75GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>272</td>\n",
       "      <td>Steven Gonzalez</td>\n",
       "      <td>High Value</td>\n",
       "      <td>MID</td>\n",
       "      <td>2hr data bundle 1.5GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1452</td>\n",
       "      <td>Nicole Pittman</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash E+CZA</td>\n",
       "      <td>Data Daily Bundle 2GB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID     Customer Name customer_segment      Region  \\\n",
       "13    1087   Laura Henderson       High Value          HS   \n",
       "20     732   Christina Bauer       High Value    Mash C+W   \n",
       "22    1774  William Martinez       High Value          HN   \n",
       "23     272   Steven Gonzalez       High Value         MID   \n",
       "29    1452    Nicole Pittman       High Value  Mash E+CZA   \n",
       "\n",
       "                                   data_subscriptions  \n",
       "13  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...  \n",
       "20  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...  \n",
       "22                           Private WiFi Bundle 75GB  \n",
       "23                              2hr data bundle 1.5GB  \n",
       "29                              Data Daily Bundle 2GB  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trevor.muchenje\\AppData\\Local\\Continuum\\anaconda3\\envs\\recsys\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\trevor.muchenje\\AppData\\Local\\Continuum\\anaconda3\\envs\\recsys\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\trevor.muchenje\\AppData\\Local\\Continuum\\anaconda3\\envs\\recsys\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### data volume\n",
    "dfc[\"Data_volume\"]=0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if dfc[\"customer_segment\"][i]==\"High Value\":\n",
    "        dfc[\"Data_volume\"][i]=np.random.randint(29860,115000)\n",
    "    elif dfc[\"customer_segment\"][i]==\"Medium Value\":\n",
    "        dfc[\"Data_volume\"][i]=np.random.randint(13694,24531)\n",
    "    else:\n",
    "        dfc[\"Data_volume\"][i]=np.random.randint(1,9741)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>customer_segment</th>\n",
       "      <th>Region</th>\n",
       "      <th>data_subscriptions</th>\n",
       "      <th>Data_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1087</td>\n",
       "      <td>Laura Henderson</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HS</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "      <td>71717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>732</td>\n",
       "      <td>Christina Bauer</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash C+W</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "      <td>71300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1774</td>\n",
       "      <td>William Martinez</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HN</td>\n",
       "      <td>Private WiFi Bundle 75GB</td>\n",
       "      <td>103584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>272</td>\n",
       "      <td>Steven Gonzalez</td>\n",
       "      <td>High Value</td>\n",
       "      <td>MID</td>\n",
       "      <td>2hr data bundle 1.5GB</td>\n",
       "      <td>52909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1452</td>\n",
       "      <td>Nicole Pittman</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash E+CZA</td>\n",
       "      <td>Data Daily Bundle 2GB</td>\n",
       "      <td>51721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID     Customer Name customer_segment      Region  \\\n",
       "13    1087   Laura Henderson       High Value          HS   \n",
       "20     732   Christina Bauer       High Value    Mash C+W   \n",
       "22    1774  William Martinez       High Value          HN   \n",
       "23     272   Steven Gonzalez       High Value         MID   \n",
       "29    1452    Nicole Pittman       High Value  Mash E+CZA   \n",
       "\n",
       "                                   data_subscriptions  Data_volume  \n",
       "13  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...        71717  \n",
       "20  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...        71300  \n",
       "22                           Private WiFi Bundle 75GB       103584  \n",
       "23                              2hr data bundle 1.5GB        52909  \n",
       "29                              Data Daily Bundle 2GB        51721  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>customer_segment</th>\n",
       "      <th>Region</th>\n",
       "      <th>data_subscriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1999</td>\n",
       "      <td>17979</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>241</td>\n",
       "      <td>Christopher Smith</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>HN</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>11094</td>\n",
       "      <td>2558</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User ID      Customer Name customer_segment Region  \\\n",
       "count     20000              20000            20000  20000   \n",
       "unique     1999              17979                3      8   \n",
       "top         241  Christopher Smith        Low Value     HN   \n",
       "freq         23                  9            11094   2558   \n",
       "\n",
       "                                       data_subscriptions  \n",
       "count                                               20000  \n",
       "unique                                                 32  \n",
       "top     WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...  \n",
       "freq                                                 1420  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Facebook + Instagram Monthly Bundle $3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Private WiFi Bundle 75GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>WhatsApp Daily Balance 20MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Data Daily Bundle 2GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Instagram Weekly Balance 140MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                            product_name\n",
       "0           6  Facebook + Instagram Monthly Bundle $3\n",
       "1           8                Private WiFi Bundle 75GB\n",
       "2          10             WhatsApp Daily Balance 20MB\n",
       "3          11                   Data Daily Bundle 2GB\n",
       "4          12          Instagram Weekly Balance 140MB"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### bringing in the products and their keys\n",
    "productsdf = pd.read_csv('C:\\\\Users\\\\trevor.muchenje\\\\Desktop\\\\disser\\\\products_keys.csv')\n",
    "productsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 13 to 19999\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   User ID             20000 non-null  object\n",
      " 1   Customer Name       20000 non-null  object\n",
      " 2   customer_segment    20000 non-null  object\n",
      " 3   Region              20000 non-null  object\n",
      " 4   data_subscriptions  20000 non-null  object\n",
      " 5   Data_volume         20000 non-null  int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dfc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf=dfc.merge(productsdf, left_on='data_subscriptions',right_on='product_name' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>customer_segment</th>\n",
       "      <th>Region</th>\n",
       "      <th>data_subscriptions</th>\n",
       "      <th>Data_volume</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1087</td>\n",
       "      <td>Laura Henderson</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HS</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "      <td>71717</td>\n",
       "      <td>258</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732</td>\n",
       "      <td>Christina Bauer</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash C+W</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "      <td>71300</td>\n",
       "      <td>258</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1774</td>\n",
       "      <td>William Martinez</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HN</td>\n",
       "      <td>Private WiFi Bundle 75GB</td>\n",
       "      <td>103584</td>\n",
       "      <td>8</td>\n",
       "      <td>Private WiFi Bundle 75GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272</td>\n",
       "      <td>Steven Gonzalez</td>\n",
       "      <td>High Value</td>\n",
       "      <td>MID</td>\n",
       "      <td>2hr data bundle 1.5GB</td>\n",
       "      <td>52909</td>\n",
       "      <td>188</td>\n",
       "      <td>2hr data bundle 1.5GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1452</td>\n",
       "      <td>Nicole Pittman</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash E+CZA</td>\n",
       "      <td>Data Daily Bundle 2GB</td>\n",
       "      <td>51721</td>\n",
       "      <td>11</td>\n",
       "      <td>Data Daily Bundle 2GB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User ID     Customer Name customer_segment      Region  \\\n",
       "0    1087   Laura Henderson       High Value          HS   \n",
       "1     732   Christina Bauer       High Value    Mash C+W   \n",
       "2    1774  William Martinez       High Value          HN   \n",
       "3     272   Steven Gonzalez       High Value         MID   \n",
       "4    1452    Nicole Pittman       High Value  Mash E+CZA   \n",
       "\n",
       "                                  data_subscriptions  Data_volume  product_id  \\\n",
       "0  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...        71717         258   \n",
       "1  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...        71300         258   \n",
       "2                           Private WiFi Bundle 75GB       103584           8   \n",
       "3                              2hr data bundle 1.5GB        52909         188   \n",
       "4                              Data Daily Bundle 2GB        51721          11   \n",
       "\n",
       "                                        product_name  \n",
       "0  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...  \n",
       "1  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...  \n",
       "2                           Private WiFi Bundle 75GB  \n",
       "3                              2hr data bundle 1.5GB  \n",
       "4                              Data Daily Bundle 2GB  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 0 to 19999\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   User ID             20000 non-null  object\n",
      " 1   Customer Name       20000 non-null  object\n",
      " 2   customer_segment    20000 non-null  object\n",
      " 3   Region              20000 non-null  object\n",
      " 4   data_subscriptions  20000 non-null  object\n",
      " 5   Data_volume         20000 non-null  int64 \n",
      " 6   product_id          20000 non-null  int64 \n",
      " 7   product_name        20000 non-null  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "cdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = cdf[['User ID','customer_segment','Region', 'product_id','data_subscriptions', 'Data_volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>customer_segment</th>\n",
       "      <th>Region</th>\n",
       "      <th>product_id</th>\n",
       "      <th>data_subscriptions</th>\n",
       "      <th>Data_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1087</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HS</td>\n",
       "      <td>258</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "      <td>71717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash C+W</td>\n",
       "      <td>258</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "      <td>71300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1774</td>\n",
       "      <td>High Value</td>\n",
       "      <td>HN</td>\n",
       "      <td>8</td>\n",
       "      <td>Private WiFi Bundle 75GB</td>\n",
       "      <td>103584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272</td>\n",
       "      <td>High Value</td>\n",
       "      <td>MID</td>\n",
       "      <td>188</td>\n",
       "      <td>2hr data bundle 1.5GB</td>\n",
       "      <td>52909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1452</td>\n",
       "      <td>High Value</td>\n",
       "      <td>Mash E+CZA</td>\n",
       "      <td>11</td>\n",
       "      <td>Data Daily Bundle 2GB</td>\n",
       "      <td>51721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User ID customer_segment      Region  product_id  \\\n",
       "0    1087       High Value          HS         258   \n",
       "1     732       High Value    Mash C+W         258   \n",
       "2    1774       High Value          HN           8   \n",
       "3     272       High Value         MID         188   \n",
       "4    1452       High Value  Mash E+CZA          11   \n",
       "\n",
       "                                  data_subscriptions  Data_volume  \n",
       "0  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...        71717  \n",
       "1  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...        71300  \n",
       "2                           Private WiFi Bundle 75GB       103584  \n",
       "3                              2hr data bundle 1.5GB        52909  \n",
       "4                              Data Daily Bundle 2GB        51721  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 0 to 19999\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   User ID             20000 non-null  object\n",
      " 1   customer_segment    20000 non-null  object\n",
      " 2   Region              20000 non-null  object\n",
      " 3   product_id          20000 non-null  int64 \n",
      " 4   data_subscriptions  20000 non-null  object\n",
      " 5   Data_volume         20000 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dff.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import implicit\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we make any sort of ratings matrix, it would be nice to have a lookup table that keeps track of each\n",
    "# item ID along with a description of that item. Let's make that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lookup = dff[['product_id', 'data_subscriptions']].drop_duplicates() # Only get unique item/description pairs\n",
    "#item_lookup['ProductKey'] = item_lookup.ProductKey.astype(str) # Encode as strings for future lookup ease\n",
    "item_lookup['product_id'] = item_lookup.product_id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>data_subscriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Private WiFi Bundle 75GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188</td>\n",
       "      <td>2hr data bundle 1.5GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Data Daily Bundle 2GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>264</td>\n",
       "      <td>eLearning Bundle 10GB $1120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                 data_subscriptions\n",
       "0         258  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...\n",
       "2           8                           Private WiFi Bundle 75GB\n",
       "3         188                              2hr data bundle 1.5GB\n",
       "4          11                              Data Daily Bundle 2GB\n",
       "5         264                        eLearning Bundle 10GB $1120"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32 entries, 0 to 8936\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   product_id          32 non-null     int32 \n",
      " 1   data_subscriptions  32 non-null     object\n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 640.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "item_lookup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 0 to 19999\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   User ID             20000 non-null  object\n",
      " 1   customer_segment    20000 non-null  object\n",
      " 2   Region              20000 non-null  object\n",
      " 3   product_id          20000 non-null  int64 \n",
      " 4   data_subscriptions  20000 non-null  object\n",
      " 5   Data_volume         20000 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dff.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group purchase quantities together by ProductKey and item ID Change any sums that equal zero to one \n",
    "(this can happen if items were returned, but we want to indicate that the user actually purchased the item instead of \n",
    " assuming no interaction between the user and the item ever took place) Only include customers with a positive purchase \n",
    "total to eliminate possible errors Set up our sparse ratings matrix This last step is especially important if you don't \n",
    "want to have unnecessary memory issues! If you think about it, our matrix is going to contain thousands of items and \n",
    "thousands of users with a user/item value required for every possible combination. That is a LARGE matrix, so we can \n",
    "save a lot of memory by keeping the matrix sparse and only saving the locations and values of items that are not zero.\n",
    "\n",
    "The code below will finish the preprocessing steps necessary for our final ratings sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trevor.muchenje\\AppData\\Local\\Continuum\\anaconda3\\envs\\recsys\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dff['User ID'] = dff['User ID'].astype(int) # Convert to int for userid\n",
    "dff = dff[['product_id', 'Data_volume', 'User ID']] # Get rid of unnecessary info\n",
    "grouped_cleaned = dff.groupby(['User ID', 'product_id']).sum().reset_index() # Group together\n",
    "grouped_cleaned.Data_volume.loc[grouped_cleaned.Data_volume == 0] = 1 # Replace a sum of zero purchases with a one to\n",
    "# indicate purchased\n",
    "grouped_purchased = grouped_cleaned.query('Data_volume > 0') # Only get customers where purchase totals were positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>product_id</th>\n",
       "      <th>Data_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>16504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>19707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>8971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>7665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>7708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID  product_id  Data_volume\n",
       "0        1         125        16504\n",
       "1        1         140        19707\n",
       "2        1         149         8971\n",
       "3        1         186         7665\n",
       "4        1         255         7708"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_purchased.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16796 entries, 0 to 16795\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   User ID      16796 non-null  int64\n",
      " 1   product_id   16796 non-null  int64\n",
      " 2   Data_volume  16796 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 524.9 KB\n"
     ]
    }
   ],
   "source": [
    "grouped_purchased.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of representing an explicit rating, the data volume can represent a \"confidence\" in terms of how strong the\n",
    "interaction was. Items with a larger number of data volumes by a customer can carry more weight in our ratings matrix of\n",
    "purchases.\n",
    "\n",
    "Our last step is to create the sparse ratings matrix of users and items utilizing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = list(np.sort(grouped_purchased['User ID'].unique())) # Getting our unique customers\n",
    "products = list(grouped_purchased.product_id.unique()) # Getting our unique products that were purchased\n",
    "quantity = list(grouped_purchased.Data_volume) # All of our purchases\n",
    "\n",
    "cat_type1 = CategoricalDtype(categories=customers)\n",
    "rows = grouped_purchased['User ID'].astype(cat_type1).cat.codes \n",
    "# Get the associated row indices\n",
    "\n",
    "cat_type2 = CategoricalDtype(categories=products)\n",
    "cols = grouped_purchased.product_id.astype(cat_type2).cat.codes \n",
    "# Get the associated column indices\n",
    "\n",
    "purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1999x32 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 16796 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchases_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1999 customers with 32 items. For these user/item interactions, 16885 of these items had a purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.7431215607804"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = purchases_sparse.shape[0]*purchases_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(purchases_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73.60% of the interaction matrix is sparse. For collaborative filtering to work, the maximum sparsity you could get away with would probably be about 99.5% or so. \n",
    "We are well below this, so we should be able to get decent results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Training and Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically in Machine Learning applications, we need to test whether the model we just trained is any good on new data it hasn't yet seen before from the training phase. We do this by creating a test set completely separate from the training set. Usually this is fairly simple: just take a random sample of the training example rows in our feature matrix and separate it away from the training set. That normally looks like this:\n",
    "\n",
    "With collaborative filtering, that's not going to work because you need all of the user/item interactions to find the proper matrix factorization. A better method is to hide a certain percentage of the user/item interactions from the model during the training phase chosen at random. Then, check during the test phase how many of the items that were recommended the user actually ended up purchasing in the end. Ideally, you would ultimately test your recommendations with some kind of A/B test or utilizing data from a time series where all data prior to a certain point in time is used for training while data after a certain period of time is used for testing.\n",
    "\n",
    "For this example, because the time period is only 8 months and because of the purchasing type (products), it is most likely products won't be purchased again in a short time period anyway. This will be a better test. You can see an example here:\n",
    "\n",
    "Our test set is an exact copy of our original data. The training set, however, will mask a random percentage of user/item interactions and act as if the user never purchased the item (making it a sparse entry with a zero). We then check in the test set which items were recommended to the user that they ended up actually purchasing. If the users frequently ended up purchasing the items most recommended to them by the system, we can conclude the system seems to be working.\n",
    "\n",
    "As an additional check, we can compare our system to simply recommending the most popular items to every user (beating popularity is a bit difficult). This will be our baseline.\n",
    "\n",
    "This method of testing isn't necessarily the \"correct\" answer, because it depends on how you want to use the recommender system. However, it is a practical way of testing performance I will use for this example.\n",
    "\n",
    "Now that we have a plan on how to separate our training and testing sets, let's create a function that can do this for us. We will also import the random library and set a seed so that you will see the same results as I did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return our training set, a test set that has been binarized to 0/1 for purchased/not purchased, and a list of which users had at least one item masked. We will test the performance of the recommender system on these users only. I am masking 20% of the user/item interactions for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_train, product_test, product_users_altered = make_train(purchases_sparse, pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our train/test split, it is time to implement the alternating least squares algorithm from the Hu, Koren, and Volinsky paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ALS for Implicit Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_weighted_ALS(training_set, lambda_val = 0.1, alpha = 40, iterations = 10, rank_size = 20, seed = 0):\n",
    "    '''\n",
    "    Implicit weighted ALS taken from Hu, Koren, and Volinsky 2008. Designed for alternating least squares and implicit\n",
    "    feedback based collaborative filtering. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - Our matrix of ratings with shape m x n, where m is the number of users and n is the number of items.\n",
    "    Should be a sparse csr matrix to save space. \n",
    "    \n",
    "    lambda_val - Used for regularization during alternating least squares. Increasing this value may increase bias\n",
    "    but decrease variance. Default is 0.1. \n",
    "    \n",
    "    alpha - The parameter associated with the confidence matrix discussed in the paper, where Cui = 1 + alpha*Rui. \n",
    "    The paper found a default of 40 most effective. Decreasing this will decrease the variability in confidence between\n",
    "    various ratings.\n",
    "    \n",
    "    iterations - The number of times to alternate between both user feature vector and item feature vector in\n",
    "    alternating least squares. More iterations will allow better convergence at the cost of increased computation. \n",
    "    The authors found 10 iterations was sufficient, but more may be required to converge. \n",
    "    \n",
    "    rank_size - The number of latent features in the user/item feature vectors. The paper recommends varying this \n",
    "    between 20-200. Increasing the number of features may overfit but could reduce bias. \n",
    "    \n",
    "    seed - Set the seed for reproducible results\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The feature vectors for users and items. The dot product of these feature vectors should give you the expected \n",
    "    \"rating\" at each point in your original matrix. \n",
    "    '''\n",
    "    \n",
    "    # first set up our confidence matrix\n",
    "    \n",
    "    conf = (alpha*training_set) # To allow the matrix to stay sparse, I will add one later when each row is taken \n",
    "                                # and converted to dense. \n",
    "    num_user = conf.shape[0]\n",
    "    num_item = conf.shape[1] # Get the size of our original ratings matrix, m x n\n",
    "    \n",
    "    # initialize our X/Y feature vectors randomly with a set seed\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    \n",
    "    X = sparse.csr_matrix(rstate.normal(size = (num_user, rank_size))) # Random numbers in a m x rank shape\n",
    "    Y = sparse.csr_matrix(rstate.normal(size = (num_item, rank_size))) # Normally this would be rank x n but we can \n",
    "                                                                 # transpose at the end. Makes calculation more simple.\n",
    "    X_eye = sparse.eye(num_user)\n",
    "    Y_eye = sparse.eye(num_item)\n",
    "    lambda_eye = lambda_val * sparse.eye(rank_size) # Our regularization term lambda*I. \n",
    "    \n",
    "    # We can compute this before iteration starts. \n",
    "    \n",
    "    # Begin iterations\n",
    "   \n",
    "    for iter_step in range(iterations): # Iterate back and forth between solving X given fixed Y and vice versa\n",
    "        # Compute yTy and xTx at beginning of each iteration to save computing time\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "        # Being iteration to solve for X based on fixed Y\n",
    "        for u in range(num_user):\n",
    "            conf_samp = conf[u,:].toarray() # Grab user row from confidence matrix and convert to dense\n",
    "            pref = conf_samp.copy() \n",
    "            pref[pref != 0] = 1 # Create binarized preference vector \n",
    "            CuI = sparse.diags(conf_samp, [0]) # Get Cu - I term, which is just CuI since we never added 1\n",
    "            yTCuIY = Y.T.dot(CuI).dot(Y) # This is the yT(Cu-I)Y term \n",
    "            yTCupu = Y.T.dot(CuI + Y_eye).dot(pref.T) # This is the yTCuPu term, where we add the eye back in\n",
    "                                                      # Cu - I + I = Cu\n",
    "            X[u] = spsolve(yTy + yTCuIY + lambda_eye, yTCupu) \n",
    "            # Solve for Xu = ((yTy + yT(Cu-I)Y + lambda*I)^-1)yTCuPu, equation 4 from the paper  \n",
    "        # Begin iteration to solve for Y based on fixed X \n",
    "        for i in range(num_item):\n",
    "            conf_samp = conf[:,i].T.toarray() # transpose to get it in row format and convert to dense\n",
    "            pref = conf_samp.copy()\n",
    "            pref[pref != 0] = 1 # Create binarized preference vector\n",
    "            CiI = sparse.diags(conf_samp, [0]) # Get Ci - I term, which is just CiI since we never added 1\n",
    "            xTCiIX = X.T.dot(CiI).dot(X) # This is the xT(Cu-I)X term\n",
    "            xTCiPi = X.T.dot(CiI + X_eye).dot(pref.T) # This is the xTCiPi term\n",
    "            Y[i] = spsolve(xTx + xTCiIX + lambda_eye, xTCiPi)\n",
    "            # Solve for Yi = ((xTx + xT(Cu-I)X) + lambda*I)^-1)xTCiPi, equation 5 from the paper\n",
    "    # End iterations\n",
    "    return X, Y.T # Transpose at the end to make up for not being transposed at the beginning. \n",
    "                         # Y needs to be rank x n. Keep these as separate matrices for scale reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully the comments are enough to see how the code was structured. You want to keep the matrices sparse where possible to avoid memory issues! Let's try just a single iteration of the code to see how it works (it's pretty slow right now!) I will choose 20 latent factors as my rank matrix size along with an alpha of 15 and regularization of 0.1 (which I found in testing does the best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vecs, item_vecs = implicit_weighted_ALS(product_train, lambda_val = 0.1, alpha = 15, iterations = 10,rank_size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can investigate ratings for a particular user by taking the dot product between the user and item vectors (U and V). Let's look at our first user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99997556,  0.99996795, -0.15893965,  0.99997235,  0.55815283])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vecs[0,:].dot(item_vecs).toarray()[0,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speeding Up ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This method is deprecated. Please use the AlternatingLeastSquares class instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf7d89ae8114ef1a95c59528bc07911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# alpha = 15\n",
    "# user_vecs, item_vecs = implicit.alternating_least_squares((product_train*alpha).astype('double'), \n",
    "#                                                           factors=20, \n",
    "#                                                           regularization = 0.1, \n",
    "#                                                          iterations = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This method is deprecated. Please use the AlternatingLeastSquares class instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1d45da6e584d248151f4f04d87dd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 5\n",
    "user_vecs, item_vecs = implicit.alternating_least_squares((product_train*alpha).astype('double'), \n",
    "                                                          factors=20, \n",
    "                                                          regularization = 0.1, \n",
    "                                                         iterations = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that our training set had 20% of the purchases masked? This will allow us to evaluate the performance of our recommender system. Essentially, we need to see if the order of recommendations given for each user matches the items they ended up purchasing. A commonly used metric for this kind of problem is the area under the Receiver Operating Characteristic (or ROC) curve. A greater area under the curve means we are recommending items that end up being purchased near the top of the list of recommended items. Usually this metric is used in more typical binary classification problems to identify how well a model can predict a positive example vs. a negative one. It will also work well for our purposes of ranking recommendations.\n",
    "\n",
    "In order to do that, we need to write a function that can calculate a mean area under the curve (AUC) for any user that had at least one masked item. As a benchmark, we will also calculate what the mean AUC would have been if we had simply recommended the most popular items. Popularity tends to be hard to beat in most recommender system problems, so it makes a good comparison.\n",
    "\n",
    "First, let's make a simple function that can calculate our AUC. Scikit-learn has one we can alter a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, utilize this helper function inside of a second function that will calculate the AUC for each user in our training set that had at least one item masked. It should also calculate AUC for the most popular items for our users to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    \n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this function to see how our recommender system is doing. To use this function, we will need to transform our output from the ALS function to csr_matrix format and transpose the item vectors. The original pure Python version output the user and item vectors into the correct format already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.517, 0.611)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mean_auc(product_train, product_users_altered, \n",
    "              [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)\n",
    "# AUC for our recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our recommender system could not beat popularity. Our system had a mean AUC of 0.511, while the popular item benchmark had a higher AUC of 0.624. You can go back and tune the hyperparameters if you wish to see if you can get a higher AUC score. Ideally, you would have separate train, cross-validation, and test sets so that you aren't overfitting while tuning the hyperparameters, but this setup is adequate to demonstrate how to check that the system is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Recommendation Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our recommender system trained and have proven it beats the benchmark of popularity. An AUC of 0.87 means the system is recommending items the user in fact had purchased in the test set far more frequently than items the user never ended up purchasing. To see an example of how it works, let's examine the recommendations given to a particular user and decide subjectively if they make any sense.\n",
    "\n",
    "First, however, we need to find a way of retrieving the items already purchased by a user in the training set. Initially, we will create an array of our customers and items we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_arr = np.array(customers) # Array of customer IDs from the ratings matrix\n",
    "products_arr = np.array(products) # Array of product IDs from the ratings matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create a function that will return a list of the item descriptions from our earlier created item lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_purchased(customer_id, mf_train, customers_list, products_list, item_lookup):\n",
    "    '''\n",
    "    This just tells me which items have been already purchased by a specific user in the training set. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    customer_id - Input the customer's id number that you want to see prior purchases of at least once\n",
    "    \n",
    "    mf_train - The initial ratings training set used (without weights applied)\n",
    "    \n",
    "    customers_list - The array of customers used in the ratings matrix\n",
    "    \n",
    "    products_list - The array of products used in the ratings matrix\n",
    "    \n",
    "    item_lookup - A simple pandas dataframe of the unique product ID/product descriptions available\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    A list of item IDs and item descriptions for a particular customer that were already purchased in the training set\n",
    "    '''\n",
    "    cust_ind = np.where(customers_list == customer_id)[0][0] # Returns the index row of our customer id\n",
    "    purchased_ind = mf_train[cust_ind,:].nonzero()[1] # Get column indices of purchased items\n",
    "    prod_codes = products_list[purchased_ind] # Get the stock codes for our purchased items\n",
    "    return item_lookup.loc[item_lookup.product_id.isin(prod_codes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to look these up by a customer's ID. Looking at the list of customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_arr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([125, 140, 149, 186, 255], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_arr[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the first customer listed has an ID of 1. Let's examine their purchases from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>data_subscriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>125</td>\n",
       "      <td>Data Daily Bundle 40MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>140</td>\n",
       "      <td>Daily Data Bouquet 40MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8910</th>\n",
       "      <td>290</td>\n",
       "      <td>Data Weekly Bouquet 160MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>186</td>\n",
       "      <td>Daily Data Bouquet 80MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id         data_subscriptions\n",
       "3970         125     Data Daily Bundle 40MB\n",
       "3974         140    Daily Data Bouquet 40MB\n",
       "8910         290  Data Weekly Bouquet 160MB\n",
       "8916         186    Daily Data Bouquet 80MB"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_items_purchased(1, product_train, customers_arr, products_arr, item_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the customer purchased Bike and bike related item. What items does the recommender system say this customer should purchase? We need to create another function that does this. Let's also import the MinMaxScaler from scikit-learn to help with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_items(customer_id, mf_train, user_vecs, item_vecs, customer_list, item_list, item_lookup, num_items = 3):\n",
    "    '''\n",
    "    This function will return the top recommended items to our users \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    customer_id - Input the customer's id number that you want to get recommendations for\n",
    "    \n",
    "    mf_train - The training matrix you used for matrix factorization fitting\n",
    "    \n",
    "    user_vecs - the user vectors from your fitted matrix factorization\n",
    "    \n",
    "    item_vecs - the item vectors from your fitted matrix factorization\n",
    "    \n",
    "    customer_list - an array of the customer's ID numbers that make up the rows of your ratings matrix \n",
    "                    (in order of matrix)\n",
    "    \n",
    "    item_list - an array of the products that make up the columns of your ratings matrix\n",
    "                    (in order of matrix)\n",
    "    \n",
    "    item_lookup - A simple pandas dataframe of the unique product ID/product descriptions available\n",
    "    \n",
    "    num_items - The number of items you want to recommend in order of best recommendations. Default is 10. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - The top n recommendations chosen based on the user/item vectors for items never interacted with/purchased\n",
    "    '''\n",
    "    \n",
    "    cust_ind = np.where(customer_list == customer_id)[0][0] # Returns the index row of our customer id\n",
    "    pref_vec = mf_train[cust_ind,:].toarray() # Get the ratings from the training set ratings matrix\n",
    "    pref_vec = pref_vec.reshape(-1) + 1 # Add 1 to everything, so that items not purchased yet become equal to 1\n",
    "    pref_vec[pref_vec > 1] = 0 # Make everything already purchased zero\n",
    "    rec_vector = user_vecs[cust_ind,:].dot(item_vecs.T) # Get dot product of user vector and all item vectors\n",
    "    # Scale this recommendation vector between 0 and 1\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0] \n",
    "    recommend_vector = pref_vec*rec_vector_scaled \n",
    "    # Items already purchased have their recommendation multiplied by zero\n",
    "    product_idx = np.argsort(recommend_vector)[::-1][:num_items] # Sort the indices of the items into order \n",
    "    # of best recommendations\n",
    "    rec_list = [] # start empty list to store items\n",
    "    for index in product_idx:\n",
    "        code = item_list[index]\n",
    "        rec_list.append([code, item_lookup.data_subscriptions.loc[item_lookup.product_id == code].iloc[0]]) \n",
    "        # Append our descriptions to the list\n",
    "    codes = [item[0] for item in rec_list]\n",
    "    descriptions = [item[1] for item in rec_list]\n",
    "    final_frame = pd.DataFrame({'ProductKey': codes, \"Product_Name\" : descriptions}) # Create a dataframe \n",
    "    return final_frame[['ProductKey', 'Product_Name']] # Switch order of columns around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, this will retrieve the N highest ranking dot products between our user and item vectors for a particular user. Items already purchased are not recommended to the user. For now, let's use a default of 10 items and see what the recommender system decides to pick for our customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>Product_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262</td>\n",
       "      <td>Daily Data Bouquet 20MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>Twitter (140MB)+ LinkedIn 70MB + 140MB Sasai B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>179</td>\n",
       "      <td>WhatsApp (20MB)+ Pinterest 10MB + 20MB Sasai B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductKey                                       Product_Name\n",
       "0         262                            Daily Data Bouquet 20MB\n",
       "1         220  Twitter (140MB)+ LinkedIn 70MB + 140MB Sasai B...\n",
       "2         179  WhatsApp (20MB)+ Pinterest 10MB + 20MB Sasai B..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_items(1, product_train, user_vecs, item_vecs, customers_arr, products_arr, item_lookup,num_items = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These recommendations seem quite good! Remember that the recommendation system has no real understanding of what a Bike product is. All it knows is the purchase history. It identified that people purchasing Bike product may also want to purchase bike of a differing use. The recommender system also suggests Hydration Pack, which is bike rider need. I personally was blown away by how well the system seems to pick up on these sorts of shopping patterns. Let's try another user that hasn't made a large number of purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>data_subscriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8910</th>\n",
       "      <td>290</td>\n",
       "      <td>Data Weekly Bouquet 160MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>263</td>\n",
       "      <td>1hr data bundle 1GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>155</td>\n",
       "      <td>Data Weekly Bundle 300MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8936</th>\n",
       "      <td>149</td>\n",
       "      <td>Data Daily Bundle 600MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id         data_subscriptions\n",
       "8910         290  Data Weekly Bouquet 160MB\n",
       "8911         263        1hr data bundle 1GB\n",
       "8921         155   Data Weekly Bundle 300MB\n",
       "8936         149    Data Daily Bundle 600MB"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_items_purchased(29, product_train, customers_arr, products_arr, item_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>Product_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264</td>\n",
       "      <td>eLearning Bundle 10GB $1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>Twitter (140MB)+ LinkedIn 70MB + 140MB Sasai B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductKey                                       Product_Name\n",
       "0         264                        eLearning Bundle 10GB $1120\n",
       "1         258  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...\n",
       "2         220  Twitter (140MB)+ LinkedIn 70MB + 140MB Sasai B..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_items(29, product_train, user_vecs, item_vecs, customers_arr, products_arr, item_lookup,\n",
    "                       num_items = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It certainly picked up on the bike theme along with accessories items. Again, these recommendations seem very impressive given the system doesn't understand the content behind the recommendations. Let's try one more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>data_subscriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Data Daily Bundle 2GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>182</td>\n",
       "      <td>Twitter (45MB)+ LinkedIn 25MB + 45MB Sasai Bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>197</td>\n",
       "      <td>Data Weekly Bundle 350MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>180</td>\n",
       "      <td>WhatsApp (45MB)+ Pinterest 25MB + 45MB Sasai B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8913</th>\n",
       "      <td>256</td>\n",
       "      <td>Instagram (20MB) + 20MB Sasai Bouquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>186</td>\n",
       "      <td>Daily Data Bouquet 80MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>255</td>\n",
       "      <td>Facebook (45MB)+ SnapChat 25MB + 45MB Sasai Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>155</td>\n",
       "      <td>Data Weekly Bundle 300MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id                                 data_subscriptions\n",
       "0            258  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...\n",
       "4             11                              Data Daily Bundle 2GB\n",
       "3977         182  Twitter (45MB)+ LinkedIn 25MB + 45MB Sasai Bou...\n",
       "3997         197                           Data Weekly Bundle 350MB\n",
       "8909         180  WhatsApp (45MB)+ Pinterest 25MB + 45MB Sasai B...\n",
       "8913         256              Instagram (20MB) + 20MB Sasai Bouquet\n",
       "8916         186                            Daily Data Bouquet 80MB\n",
       "8920         255  Facebook (45MB)+ SnapChat 25MB + 45MB Sasai Bo...\n",
       "8921         155                           Data Weekly Bundle 300MB"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_items_purchased(120, product_train, customers_arr, products_arr, item_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This customer seems like they are buying products suitable for bike and accessories. What other items does the recommender system think they might like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>Product_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>Data Daily Bundle 600MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>Data Daily Bundle 40MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>Twitter (140MB)+ LinkedIn 70MB + 140MB Sasai B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226</td>\n",
       "      <td>Facebook + Instagram Daily Bundle $0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262</td>\n",
       "      <td>Daily Data Bouquet 20MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductKey                                       Product_Name\n",
       "0         149                            Data Daily Bundle 600MB\n",
       "1         125                             Data Daily Bundle 40MB\n",
       "2         220  Twitter (140MB)+ LinkedIn 70MB + 140MB Sasai B...\n",
       "3         226             Facebook + Instagram Daily Bundle $0.3\n",
       "4         262                            Daily Data Bouquet 20MB"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_items(120, product_train, user_vecs, item_vecs, customers_arr, products_arr, item_lookup,\n",
    "                       num_items = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### more trails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>data_subscriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>150</td>\n",
       "      <td>Private WiFi Bundle  15GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>142</td>\n",
       "      <td>Daily Data Bouquet 250MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>182</td>\n",
       "      <td>Twitter (45MB)+ LinkedIn 25MB + 45MB Sasai Bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>198</td>\n",
       "      <td>Data Weekly Bundle 700MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8906</th>\n",
       "      <td>262</td>\n",
       "      <td>Daily Data Bouquet 20MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>263</td>\n",
       "      <td>1hr data bundle 1GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>226</td>\n",
       "      <td>Facebook + Instagram Daily Bundle $0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id                                 data_subscriptions\n",
       "0            258  WhatsApp (400MB)+ Pinterest 200MB + 400MB Sasa...\n",
       "17           150                          Private WiFi Bundle  15GB\n",
       "3969         142                           Daily Data Bouquet 250MB\n",
       "3977         182  Twitter (45MB)+ LinkedIn 25MB + 45MB Sasai Bou...\n",
       "3990         198                           Data Weekly Bundle 700MB\n",
       "8906         262                            Daily Data Bouquet 20MB\n",
       "8911         263                                1hr data bundle 1GB\n",
       "8923         226             Facebook + Instagram Daily Bundle $0.3"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_items_purchased(1500, product_train, customers_arr, products_arr, item_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>Product_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>Daily Data Bouquet 80MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>Data Daily Bundle 40MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>Facebook (45MB)+ SnapChat 25MB + 45MB Sasai Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>Instagram (20MB) + 20MB Sasai Bouquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188</td>\n",
       "      <td>2hr data bundle 1.5GB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductKey                                       Product_Name\n",
       "0         186                            Daily Data Bouquet 80MB\n",
       "1         125                             Data Daily Bundle 40MB\n",
       "2         255  Facebook (45MB)+ SnapChat 25MB + 45MB Sasai Bo...\n",
       "3         256              Instagram (20MB) + 20MB Sasai Bouquet\n",
       "4         188                              2hr data bundle 1.5GB"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_items(1500, product_train, user_vecs, item_vecs, customers_arr, products_arr, item_lookup,\n",
    "                       num_items = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
